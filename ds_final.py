# -*- coding: utf-8 -*-
"""ds final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1E3rPeBc1ET-dM5FW_WPYenpJdVP2JUtW
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import pandas as pd
import os
import matplotlib.pyplot as plt
import seaborn as sns
import cv2
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.decomposition import PCA
from sklearn.svm import SVC
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
from sklearn.cluster import KMeans
from collections import Counter

# Set dataset path
train_dir = "/content/drive/MyDrive/DS CATARACT /train"

def load_images(directory, img_size=(128, 128)):
    images, labels, original_images, processed_images = [], [], [], []
    if not os.path.exists(directory):
        raise FileNotFoundError(f"Dataset directory not found: {directory}")

    class_labels = os.listdir(directory)
    for label in class_labels:
        class_dir = os.path.join(directory, label)
        for img_name in os.listdir(class_dir):
            img_path = os.path.join(class_dir, img_name)
            img = cv2.imread(img_path)
            if img is not None:
                original_images.append(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
                img = cv2.resize(img, img_size)
                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
                img = cv2.GaussianBlur(img, (5, 5), 0)
                processed_images.append(img)
                images.append(img.flatten())
                labels.append(label)
    return np.array(images), np.array(labels), original_images, processed_images

# Load images
X, y, original_images, processed_images = load_images(train_dir)

# Display original and processed images
fig, axes = plt.subplots(2, 10, figsize=(20, 5))
for i in range(10):
    axes[0, i].imshow(original_images[i])
    axes[0, i].set_title(f"Original {i}")
    axes[0, i].axis("off")

    axes[1, i].imshow(processed_images[i], cmap='gray')
    axes[1, i].set_title(f"Processed {i}")
    axes[1, i].axis("off")
plt.show()

# Preprocessing
le = LabelEncoder()
y_encoded = le.fit_transform(y)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
pca = PCA(n_components=35)
X_pca = pca.fit_transform(X_scaled)

# Clustering using KMeans
num_clusters = 3
kmeans = KMeans(n_clusters=num_clusters, random_state=42, n_init=10)
kmeans.fit(X_pca)
cluster_labels = kmeans.labels_

# Display Images per Cluster
def display_cluster_images(original_images, cluster_labels, cluster_id, num_images=9):
    cluster_indices = np.where(cluster_labels == cluster_id)[0][:num_images]
    plt.figure(figsize=(5, 5))
    for i, idx in enumerate(cluster_indices):
        plt.subplot(3, 3, i + 1)
        plt.imshow(original_images[idx])
        plt.title(f"Cluster {cluster_id}")
        plt.axis("off")
    plt.show()

for cluster_id in range(num_clusters):
    display_cluster_images(original_images, cluster_labels, cluster_id)

# Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X_pca, y_encoded, test_size=0.2, random_state=42)

# SVM Classification with optimized parameters
svm_model = SVC(C=0.8, gamma='scale', kernel='rbf')
svm_model.fit(X_train, y_train)
y_pred = svm_model.predict(X_test)

# Cross-validation to check generalization
cv_scores = cross_val_score(svm_model, X_pca, y_encoded, cv=20)
cross_val_accuracy = np.mean(cv_scores)
print(f'Cross-Validation Accuracy: {cross_val_accuracy * 100:.2f}%')

# Evaluation
train_accuracy = accuracy_score(y_train, svm_model.predict(X_train))
test_accuracy = accuracy_score(y_test, y_pred)
print(f'Training Accuracy: {train_accuracy * 100:.2f}%')
print(f'Testing Accuracy: {test_accuracy * 100:.2f}%')
print("Classification Report:")
print(classification_report(y_test, y_pred))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
cm_accuracy = np.trace(cm) / np.sum(cm)  # Compute accuracy from confusion matrix
print(f'Confusion Matrix Accuracy: {cm_accuracy * 100:.2f}%')

sns.heatmap(cm, annot=True, fmt='d')
plt.title("Confusion Matrix")
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()

# Display classified test images
fig, axes = plt.subplots(2, 5, figsize=(15, 6))
for i in range(10):
    img = original_images[i]
    axes[i // 5, i % 5].imshow(img)
    axes[i // 5, i % 5].set_title(f"Predicted: {le.inverse_transform([y_pred[i]])[0]}")
    axes[i // 5, i % 5].axis("off")
plt.show()

# Function to Classify New Image
def classify_new_image(image_path):
    img = cv2.imread(image_path)
    if img is not None:
        img = cv2.resize(img, (128, 128))
        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        img = cv2.GaussianBlur(img, (5, 5), 0)
        img_flattened = img.flatten().reshape(1, -1)
        img_scaled = scaler.transform(img_flattened)
        img_pca = pca.transform(img_scaled)
        prediction = svm_model.predict(img_pca)
        cluster_prediction = kmeans.predict(img_pca)
        plt.imshow(img, cmap='gray')
        plt.title(f"Prediction: {le.inverse_transform(prediction)[0]}, Cluster: {cluster_prediction[0]}")
        plt.axis('off')
        plt.show()
    else:
        print("Image not found or unable to read")

# Classify a new image
new_image_path = "/content/Screenshot 2025-03-17 094401.png"
classify_new_image(new_image_path)

# Cluster Visualization
cluster_counts = Counter(cluster_labels)
plt.pie(cluster_counts.values(), labels=[f'Cluster {i}' for i in cluster_counts.keys()], autopct='%1.1f%%', colors=['red', 'yellow', 'green'])
plt.title("Cluster Distribution")
plt.show()

# Scatter Plot for Clusters
plt.scatter(range(len(X_pca)), X_pca[:, 0], c=cluster_labels, cmap='rainbow', alpha=0.7, edgecolors='k')
plt.xlabel("Sample Index")
plt.ylabel("Feature 1")
plt.title("Cluster Visualization")
plt.colorbar(label="Cluster")
plt.show()